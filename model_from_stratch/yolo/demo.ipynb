{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/pydantic/main.py:347: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "from Data_utils import *\n",
    "from constants import *\n",
    "\n",
    "# Creating a dataset object \n",
    "dataset = Dataset( \n",
    "\tcsv_file=\"../../og/train.csv\", \n",
    "\timage_dir=\"../../og/images/\", \n",
    "\tlabel_dir=\"../../og/labels/\", \n",
    "\tgrid_sizes=[13, 26, 52], \n",
    "\tanchors=ANCHORS, \n",
    "\ttransform=test_transform \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxes:  [[0.8971061093247589, 0.947481243301179, 0.14576634512325826, 0.10503751339764193, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5083487940630798, 0.5357142857142857, 0.3358070500927644, 0.40909090909090906, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5053590568060021, 0.5042872454448017, 0.06323687031082521, 0.08896034297963559, 0.0], [0.49249732047159694, 0.439978563772776, 0.028938906752411526, 0.031082529474812402, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.43837084673097537, 0.7904608788853161, 0.16934619506966775, 0.14898177920685954, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5213347921225382, 0.49999999999999944, 0.9573304157549234, 0.9999999999999989, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.9271799628942486, 0.9285714285714286, 0.1456400742115028, 0.09461966604823743, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.31350482315112543, 0.7877813504823152, 0.2175777063236871, 0.17363344051446958, 1.0], [0.7588424437299035, 0.837620578778135, 0.4823151125401929, 0.32475884244372993, 1.0], [0.8279742765273312, 0.21704180064308684, 0.3440514469453376, 0.4319399785637728, 1.0], [0.2620578778135048, 0.3542336548767417, 0.5241157556270096, 0.6312968917470525, 1.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/04182cd6-334.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/003b87fb-2652.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/01d011d4-3227.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/051b7863-3175.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/02837023-973.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/03bdc3ab-1771.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/024a9a6a-1259.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/0209cb22-192.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/002559d6-3389.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.712800875273523, 0.04048140043763676, 0.574398249452954, 0.07658643326039387, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.15434083601286178, 0.2872454448017148, 0.30868167202572355, 0.5744908896034296, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8107606679035251, 0.5231910946196661, 0.11317254174397036, 0.11873840445269025, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.39764201500535906, 0.4983922829581994, 0.4287245444801714, 0.22722400857449082, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6307609860664524, 0.46248660235798494, 0.7384780278670954, 0.9228295819935691, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5911039657020365, 0.3821007502679528, 0.13183279742765258, 0.19399785637727754, 0.0], [0.6913183279742765, 0.0632368703108253, 0.09646302250803857, 0.1264737406216506, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8167903525046385, 0.8065862708719846, 0.24582560296846018, 0.06029684601113103, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.38263665594855306, 0.4619506966773848, 0.1286173633440514, 0.16720257234726696, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8129689174705251, 0.49999999999999994, 0.3740621650589493, 0.9999999999999999, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.3440514469453376, 0.7293676312968919, 0.6881028938906752, 0.5412647374062165, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5060296846011131, 0.5051020408163265, 0.17346938775510196, 0.18274582560296843, 0.0], [0.3232838589981447, 0.9429499072356213, 0.043599257884972216, 0.047309833024118716, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5091103965702036, 0.2561629153269025, 0.0664523043944265, 0.04930332261521972, 0.0], [0.5262593783494105, 0.7743837084673098, 0.10932475884244376, 0.2004287245444803, 0.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/02e347fe-4260.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/04306e68-3695.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/0442aa25-2234.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/034823c6-3769.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/032f1e92-1386.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/03ed9014-1870.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/01c3f71d-3973.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6961414790996784, 0.6666666666666667, 0.3890675241157557, 0.29581993569131837, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8992497320471596, 0.7036441586280816, 0.20150053590568062, 0.5026795284030011, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.3756698821007503, 0.6361200428724544, 0.3890675241157557, 0.6355841371918541, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.43676312968917474, 0.6050375133976421, 0.8735262593783495, 0.789924973204716, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5042872454448016, 0.5032154340836013, 0.1554126473740621, 0.2004287245444801, 2.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.33673469387755106, 0.6544526901669759, 0.39517625231910947, 0.3923933209647496, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8971061093247589, 0.947481243301179, 0.14576634512325826, 0.10503751339764193, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.4308905380333951, 0.664656771799629, 0.8525046382189239, 0.6706864564007421, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5153061224489796, 0.5092764378478664, 0.08998144712430431, 0.11317254174397029, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.08896034297963559, 0.15273311897106112, 0.17792068595927119, 0.30546623794212224, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.34244372990353694, 0.2132904608788853, 0.29260450160771706, 0.2057877813504823, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/059df5de-2773.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/065096e7-636.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/039b6284-172.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/032ff6b2-1923.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/02bb6b99-483.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/004860dc-348.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/02f4b69d-85.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.4990723562152134, 0.2170686456400742, 0.8014842300556586, 0.42857142857142855, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.20257234726688103, 0.7717041800643086, 0.40514469453376206, 0.4565916398713826, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8269944341372915, 0.8919294990723559, 0.11038961038961043, 0.11038961038961087, 1.0], [0.24350649350649353, 0.5960111317254174, 0.48701298701298706, 0.8079777365491652, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.3028756957328386, 0.33998144712430434, 0.6020408163265307, 0.6799628942486087, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5144694533762055, 0.6200428724544477, 0.9710610932475879, 0.7599142550911034, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.4683815648445874, 0.4062165058949625, 0.4758842443729904, 0.4780278670953912, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.39564007421150277, 0.7421150278293135, 0.40352504638218917, 0.424860853432282, 2.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.13676148796498905, 0.7795404814004376, 0.2735229759299781, 0.44091903719912473, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.33976420150053593, 0.7540192926045016, 0.4115755627009646, 0.23258306538049303, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6372912801484231, 0.8826530612244897, 0.230055658627087, 0.1734693877551021, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5766345123258307, 0.6312968917470525, 0.662379421221865, 0.6302250803858521, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/03146680-1731.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/059fb2c1-1348.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/0592eaaa-155.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/03e2dcb6-3969.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/0398a5e8-846.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/0314a9d5-2744.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/025a9bb4-3203.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/01d0bff4-2909.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.7363344051446944, 0.7416934619506966, 0.2893890675241157, 0.3472668810289388, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5916398713826366, 0.21543408360128616, 0.22722400857449088, 0.2207931404072883, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.7792068595927116, 0.5921757770632369, 0.4415862808145766, 0.8156484458735263, 1.0], [0.2416934619506967, 0.41747052518756694, 0.4833869239013934, 0.21543408360128613, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.7197213290460877, 0.6789924973204711, 0.560557341907824, 0.642015005359056, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5080385852090032, 0.49517684887459806, 0.5487674169346195, 0.8295819935691319, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6971243042671614, 0.409554730983302, 0.440630797773655, 0.813543599257884, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5797773654916513, 0.7036178107606679, 0.8126159554730984, 0.5927643784786641, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.25092764378478666, 0.5871985157699444, 0.3330241187384045, 0.4230055658627087, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.7942122186495177, 0.5530546623794212, 0.1693461950696677, 0.17577706323687026, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5310825294748122, 0.49999999999999967, 0.9378349410503746, 0.9999999999999993, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/00c885ef-2164.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/00697b75-279.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/05964560-4355.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/0451d25c-1331.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/046c4047-2090.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/03c01f08-4507.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.507421150278293, 0.47634508348794063, 0.0871985157699443, 0.11595547309833024, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.49249732047159694, 0.47856377277599144, 0.9849946409431939, 0.9571275455519829, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8840445269016698, 0.7439703153988869, 0.23191094619666047, 0.5120593692022264, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.41558441558441567, 0.45686456400742115, 0.8311688311688311, 0.6465677179962894, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6982851018220794, 0.8949624866023581, 0.15541264737406216, 0.15648445873526257, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.24397031539888683, 0.7040816326530611, 0.437847866419295, 0.5918367346938775, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.462430426716141, 0.3807977736549165, 0.924860853432282, 0.761595547309833, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6455142231947483, 0.4808533916849015, 0.09409190371991244, 0.14551422319474838, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.2829581993569132, 0.3735262593783494, 0.5659163987138264, 0.37834941050375115, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.512325830653805, 0.8520900321543408, 0.782422293676313, 0.29581993569131837, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.5369774919614149, 0.2979635584137192, 0.7952840300107182, 0.14790996784565913, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/024bf60b-75.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/057eda67-3319.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/04f18c77-2055.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/01571bed-3612.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/034dd025-2500.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.512987012987013, 0.4540816326530612, 0.35621521335807055, 0.46474953617810755, 2.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.8900742115027824, 0.6679035250463824, 0.21985157699443486, 0.6641929499072353, 1.0], [0.9661410018552875, 0.8678107606679035, 0.0658627087198514, 0.17903525046382274, 2.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.34647495361781067, 0.3877551020408164, 0.6929499072356213, 0.7755102040816326, 1.0], [0.08998144712430425, 0.1085343228200371, 0.1595547309833024, 0.19109461966604824, 2.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.592711682743837, 0.8928188638799571, 0.40300107181136113, 0.21436227224008575, 2.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.7325830653804931, 0.061629153269024656, 0.1618435155412648, 0.12325830653804931, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.16205357142857146, 0.19910714285714284, 0.04375000000000004, 0.04107142857142858, 0.0], [0.1232142857142857, 0.271875, 0.03928571428571427, 0.024107142857142848, 0.0], [0.4205357142857143, 0.7928571428571428, 0.05535714285714292, 0.08392857142857153, 0.0], [0.9169642857142857, 0.8866071428571428, 0.0625, 0.09285714285714292, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.08698030634573305, 0.9020787746170678, 0.17396061269146607, 0.1958424507658644, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.6181619256017505, 0.13183807439824946, 0.5557986870897156, 0.2636761487964989, 1.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  [[0.9131832797427651, 0.8381564844587353, 0.14362272240085744, 0.3236870310825294, 0.0]]\n",
      "!!!\n",
      "dict_keys(['image', 'bboxes'])\n",
      "dict_keys(['image', 'bboxes'])\n",
      "bboxes:  []\n",
      "!!\n",
      "dict_keys(['image', 'bboxes'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/02285be0-1426.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataloader object \n",
    "loader = torch.utils.data.DataLoader( \n",
    "\tdataset=dataset, \n",
    "\tbatch_size=1, \n",
    "\tshuffle=True, \n",
    ") \n",
    "\n",
    "# Defining the grid size and the scaled anchors \n",
    "GRID_SIZE = [19, 38, 76] \n",
    "scaled_anchors = torch.tensor(ANCHORS) / ( \n",
    "\t1 / torch.tensor(GRID_SIZE).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2) \n",
    ")\n",
    "\n",
    "# Getting a batch from the dataloader \n",
    "x, y, z = next(iter(loader))\n",
    "print(z.keys())\n",
    "\n",
    "for x,y,x in iter(loader):\n",
    "\tprint(z.keys())\n",
    "# # Getting the boxes coordinates from the labels \n",
    "# # and converting them into bounding boxes without scaling \n",
    "# boxes = [] \n",
    "# for i in range(y[0].shape[1]): \n",
    "# \tanchor = scaled_anchors[i] \n",
    "# \tboxes += convert_cells_to_bboxes( \n",
    "# \t\t\ty[i], is_predictions=False, s=y[i].shape[2], anchors=anchor \n",
    "# \t\t\t)[0] \n",
    "\n",
    "# # Applying non-maximum suppression \n",
    "# boxes = nms(boxes, iou_threshold=1, threshold=0.7) \n",
    "\n",
    "# # Plotting the image with the bounding boxes \n",
    "# plot_image(x[0].permute(1,2,0).to(\"cpu\"), boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 19, 19, 8])\n",
      "torch.Size([1, 3, 38, 38, 8])\n",
      "torch.Size([1, 3, 76, 76, 8])\n",
      "Output shapes are correct!\n"
     ]
    }
   ],
   "source": [
    "from model import *\n",
    "\n",
    "# Testing YOLO v3 model \n",
    "if __name__ == \"__main__\": \n",
    "    # Setting number of classes and image size \n",
    "    num_classes = 3\n",
    "    IMAGE_SIZE = 608\n",
    "  \n",
    "    # Creating model and testing output shapes \n",
    "    model = YOLOv3(num_classes=num_classes) \n",
    "    x = torch.randn((1, 3, IMAGE_SIZE, IMAGE_SIZE)) \n",
    "    out = model(x) \n",
    "    print(out[0].shape) \n",
    "    print(out[1].shape) \n",
    "    print(out[2].shape) \n",
    "  \n",
    "    # Asserting output shapes \n",
    "    assert model(x)[0].shape == (1, 3, IMAGE_SIZE//32, IMAGE_SIZE//32, num_classes + 5) \n",
    "    assert model(x)[1].shape == (1, 3, IMAGE_SIZE//16, IMAGE_SIZE//16, num_classes + 5) \n",
    "    assert model(x)[2].shape == (1, 3, IMAGE_SIZE//8, IMAGE_SIZE//8, num_classes + 5) \n",
    "    print(\"Output shapes are correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = np.roll(np.loadtxt(fname='/Users/fouk/Documents/cosmic-object-scanner/og/labels/0a2b8ffd-2211.txt', \n",
    "\t\t\t\t\t\tdelimiter=\" \", ndmin=2), 4, axis=1).tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4490889603429796,\n",
       "  0.6993569131832796,\n",
       "  0.5294748124330116,\n",
       "  0.5434083601286173,\n",
       "  2.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/113 [00:00<?, ?it/s]/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/pydantic/main.py:347: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/059df5de-2773.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 608, 608])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "  0%|          | 0/113 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[srcBuf length] > 0 INTERNAL ASSERT FAILED at \"/Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/OperationUtils.mm\":387, please report a bug to PyTorch. Placeholder tensor is empty!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m): \n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e) \n\u001b[0;32m---> 46\u001b[0m     \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_anchors\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Saving the model \u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_model: \n",
      "File \u001b[0;32m~/Documents/cosmic-object-scanner/model_from_stratch/yolo/model_utils.py:83\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(loader, model, optimizer, loss_fn, scaler, scaled_anchors)\u001b[0m\n\u001b[1;32m     80\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(x) \n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Calculating the loss at each scale \u001b[39;00m\n\u001b[1;32m     82\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ( \n\u001b[0;32m---> 83\u001b[0m           \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_anchors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     84\u001b[0m         \u001b[38;5;241m+\u001b[39m loss_fn(outputs[\u001b[38;5;241m1\u001b[39m], y1, scaled_anchors[\u001b[38;5;241m1\u001b[39m]) \n\u001b[1;32m     85\u001b[0m         \u001b[38;5;241m+\u001b[39m loss_fn(outputs[\u001b[38;5;241m2\u001b[39m], y2, scaled_anchors[\u001b[38;5;241m2\u001b[39m]) \n\u001b[1;32m     86\u001b[0m     ) \n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Add the loss to the list \u001b[39;00m\n\u001b[1;32m     89\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem()) \n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/cosmic-object-scanner/model_from_stratch/yolo/model_utils.py:36\u001b[0m, in \u001b[0;36mYOLOLoss.forward\u001b[0;34m(self, pred, target, anchors)\u001b[0m\n\u001b[1;32m     34\u001b[0m ious \u001b[38;5;241m=\u001b[39m iou(box_preds[obj], target[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m][obj])\u001b[38;5;241m.\u001b[39mdetach() \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Calculating Object loss \u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m object_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mious\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Predicted box coordinates \u001b[39;00m\n\u001b[1;32m     41\u001b[0m pred[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(pred[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]) \n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/loss.py:535\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/nn/functional.py:3383\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3380\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3382\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m-> 3383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [srcBuf length] > 0 INTERNAL ASSERT FAILED at \"/Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/OperationUtils.mm\":387, please report a bug to PyTorch. Placeholder tensor is empty!"
     ]
    }
   ],
   "source": [
    "from model_utils import *\n",
    "from torch import optim\n",
    "from constants import *\n",
    "from model import *\n",
    "\n",
    "# Creating the model from YOLOv3 class \n",
    "model = YOLOv3(in_channels=3,num_classes=3).to(device) \n",
    "  \n",
    "# Defining the optimizer \n",
    "optimizer = optim.Adam(model.parameters(), lr = leanring_rate) \n",
    "  \n",
    "# Defining the loss function \n",
    "loss_fn = YOLOLoss() \n",
    "  \n",
    "# Defining the scaler for mixed precision training \n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "  \n",
    "# Defining the train dataset \n",
    "train_dataset = Dataset( \n",
    "    csv_file=\"../../og/train.csv\", \n",
    "    image_dir=\"../../og/images/\", \n",
    "    label_dir=\"../../og/labels/\", \n",
    "    grid_sizes=[19,38,76],\n",
    "    anchors=ANCHORS, \n",
    "    transform=train_transform \n",
    ") \n",
    "  \n",
    "# Defining the train data loader \n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset, \n",
    "    batch_size = 1, \n",
    "    num_workers = 1, \n",
    "    shuffle = True, \n",
    "    pin_memory = True, \n",
    ") \n",
    "  \n",
    "# Scaling the anchors \n",
    "scaled_anchors = ( \n",
    "    torch.tensor(ANCHORS) * \n",
    "    torch.tensor(s).unsqueeze(1).unsqueeze(1).repeat(1,3,2) \n",
    ").to(device) \n",
    "  \n",
    "# Training the model \n",
    "for e in range(1, epochs+1): \n",
    "    print(\"Epoch:\", e) \n",
    "    training_loop(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors) \n",
    "  \n",
    "    # Saving the model \n",
    "    if save_model: \n",
    "        save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/pydantic/main.py:347: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    }
   ],
   "source": [
    "from model_utils import *\n",
    "from torch import optim\n",
    "from constants import *\n",
    "from model import *\n",
    "from Data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/pydantic/main.py:347: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Applications/anaconda3/envs/ai/lib/python3.11/site-packages/pydantic/main.py:347: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  Expected `Union[float, tuple[float, float]]` but got `list` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "/Users/fouk/Documents/cosmic-object-scanner/model_from_stratch/yolo/Data_utils.py:51: UserWarning: loadtxt: input contained no data: \"../../og/labels/024bf60b-75.txt\"\n",
      "  bboxes = np.roll(np.loadtxt(fname=label_path,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "22743\n",
      "BOXES!\n",
      "LEN:  22743\n",
      "LEN:  9386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bboxes[i]))\n\u001b[0;32m---> 62\u001b[0m nms_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mnms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Plotting the image with bounding boxes \u001b[39;00m\n\u001b[1;32m     64\u001b[0m plot_image(x[i]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), nms_boxes)\n",
      "File \u001b[0;32m~/Documents/cosmic-object-scanner/model_from_stratch/yolo/utils.py:82\u001b[0m, in \u001b[0;36mnms\u001b[0;34m(bboxes, iou_threshold, threshold)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Iterate over the remaining bounding boxes. \u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m bboxes: \n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# If the bounding boxes do not overlap or if the first bounding box has \u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# a higher confidence, then add the second bounding box to the list of \u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# bounding boxes after non-maximum suppression. \u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m first_box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[43miou\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_box\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m iou_threshold: \n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# Check if box is not in bboxes_nms \u001b[39;00m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bboxes_nms: \n\u001b[1;32m     88\u001b[0m             \u001b[38;5;66;03m# Add box to bboxes_nms \u001b[39;00m\n\u001b[1;32m     89\u001b[0m             bboxes_nms\u001b[38;5;241m.\u001b[39mappend(box) \n",
      "File \u001b[0;32m~/Documents/cosmic-object-scanner/model_from_stratch/yolo/utils.py:25\u001b[0m, in \u001b[0;36miou\u001b[0;34m(box1, box2, is_pred)\u001b[0m\n\u001b[1;32m     22\u001b[0m b2_y2 \u001b[38;5;241m=\u001b[39m box2[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m box2[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Get the coordinates of the intersection rectangle \u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb1_x1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2_x1\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m y1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(b1_y1, b2_y1) \n\u001b[1;32m     27\u001b[0m x2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(b1_x2, b2_x2) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Taking a sample image and testing the model \n",
    "device = 'cpu'\n",
    "# Setting the load_model to True \n",
    "load_model = True\n",
    "  \n",
    "# Defining the model, optimizer, loss function and scaler \n",
    "model = YOLOv3(in_channels=3,num_classes=3).to('cpu') \n",
    "optimizer = optim.Adam(model.parameters(), lr = leanring_rate) \n",
    "loss_fn = YOLOLoss() \n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "  \n",
    "# Loading the checkpoint \n",
    "if load_model: \n",
    "    load_checkpoint(checkpoint_file, model, optimizer, leanring_rate) \n",
    "  \n",
    "# Defining the test dataset and data loader \n",
    "test_dataset = Dataset( \n",
    "    csv_file=\"../../og/train.csv\", \n",
    "    image_dir=\"../../og/images/\", \n",
    "    label_dir=\"../../og/labels/\", \n",
    "    anchors=ANCHORS, \n",
    "    transform=test_transform \n",
    ") \n",
    "test_loader = torch.utils.data.DataLoader( \n",
    "    test_dataset, \n",
    "    batch_size = 1, \n",
    "    num_workers = 2, \n",
    "    shuffle = True, \n",
    ") \n",
    "  \n",
    "# Getting a sample image from the test data loader \n",
    "x, y = next(iter(test_loader)) \n",
    "x = x.to(device) \n",
    "  \n",
    "model.eval() \n",
    "with torch.no_grad(): \n",
    "    # Getting the model predictions \n",
    "    output = model(x) \n",
    "    # Getting the bounding boxes from the predictions \n",
    "    bboxes = [[] for _ in range(x.shape[0])] \n",
    "    anchors = ( \n",
    "            torch.tensor(ANCHORS) \n",
    "                * torch.tensor(s).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2) \n",
    "            ).to(device) \n",
    "  \n",
    "    # Getting bounding boxes for each scale \n",
    "    for i in range(3): \n",
    "        batch_size, A, S, _, _ = output[i].shape \n",
    "        anchor = anchors[i] \n",
    "        boxes_scale_i = convert_cells_to_bboxes( \n",
    "                            output[i], anchor, s=S, is_predictions=True\n",
    "                        ) \n",
    "        for idx, (box) in enumerate(boxes_scale_i): \n",
    "            bboxes[idx] += box \n",
    "model.train() \n",
    "print(len(bboxes))\n",
    "# Plotting the image with bounding boxes for each image in the batch \n",
    "for i in range(batch_size): \n",
    "    # Applying non-max suppression to remove overlapping bounding boxes \n",
    "    print(i)\n",
    "    print(len(bboxes[i]))\n",
    "    nms_boxes = nms(bboxes[i], iou_threshold=0.5, threshold=0.5) \n",
    "    # Plotting the image with bounding boxes \n",
    "    plot_image(x[i].permute(1,2,0).detach().cpu(), nms_boxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
